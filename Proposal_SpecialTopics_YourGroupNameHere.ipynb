{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Special Topics Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "- Nessa Pantfoerder\n",
    "- Alexandra Hernandez\n",
    "- Kyle Vu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic and outline\n",
    "\n",
    "### Main topic\n",
    "The main topic will be racial bias in facial detection algorithms and the challenges and solutions associated.\n",
    "\n",
    "### Learning goal for students \n",
    "Students will be able to describe the impact of racial bias in facial recognition detection algorithms and propose solutions to minimize bias in facial recognition technology.\n",
    "\n",
    "### Outline of the topic\n",
    "  - Intro to Facial Recognition/Detection\n",
    "    - __The basics of facial recognition/detection algorithms__\n",
    "    - Applications of face detection in the world\n",
    "  - History of Racial Bias in Facial Recognition/Detection Algorithms\n",
    "    - __How to recognize bias__\n",
    "    - Implications of bias in algorithms\n",
    "  - Case studies on facial detection/recognition\n",
    "    - __Real world consequences of bias__\n",
    "    - Effects on those biased against in facial recognition/detection algorithms\n",
    "- Ethics/importance\n",
    "    - __Describing ethics in the world of AI/machine learning__\n",
    "    - Why are ethical algorithms important?\n",
    "    - Dangers of unethical algorithms in the real world\n",
    "- Solutions to the ethical problem(s)\n",
    "    - __Ways to mitigate racial bias__\n",
    "    - Implementation of solutions\n",
    "    - Looking to the future: What improvements are left to be made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedagogy\n",
    "\n",
    "\n",
    "### Readings\n",
    "Leslie, D. (2020). Understanding bias in facial recognition technologies: an explainer. The Alan Turing Institute. https://doi.org/10.5281/zenodo.4050457 </br>\n",
    "\n",
    "This reading covers how facial recognition has gained popularity. There are conflicting views on this technology where some view it as a great convenience for things like unlocking your phone but others are concerned it violates rights and brings up biases for people of color. The paper discusses the ethics of facial recognition technology and if a solution is feasible or if this technology should not be used at all. </br>\n",
    "This reading explains to students how biases and discrimination have been intertwined with the development of facial recognition from the very start and how these said biases are still a part of modern facial recognition. We want students to learn about the history of bias in facial recognition and about the ethical implications of continuing to use facial recognition if a solution is not found.\n",
    "\n",
    "---\n",
    "\n",
    "Perkowitz, Sidney. 2021. “The Bias in the Machine: Facial Recognition Technology and Racial Disparities.” MIT Case Studies in Social and Ethical Responsibilities of Computing, no. Winter 2021 (February). https://doi.org/10.21428/2c646de5.62272586. </br>\n",
    "\n",
    "This reading discusses how Facial Recognition Technology (FRT) can be biased and can lead to the conviction of innocent people if overly relied upon. Datasets used to train FRT are typically underrepresented by people of color, but criminal databases actually oversample people of color. Advancements in machine learning (CNNs, use of eigenfaces) have improved facial recognition capabilities of machines, but they are still certainly not infallible. </br>\n",
    "The main takeaways we want students to know are that despite their usefulness, proper care must still be taken when using FRT especially in the case of criminal prosecution. A mixture of human and machine analysis of data is typically necessary for the highest accuracy. We can try to improve ML models by training them on less biased datasets.  \n",
    "\n",
    "### Lecture description\n",
    "The lecture will cover a brief introduction to facial recognition by Nessa and the history of racial bias in these algorithms by Kyle. We will then discuss case studies of how bias has shown up in facial recognition by Nessa and the importance of ethical algorithms by Alexandra. We will conclude with a discussion of possible ways to mitigate biases in facial recognition algorithms by Kyle. \n",
    "\n",
    "### Active learning\n",
    "#### How racial biases are formed in programming: A demo\n",
    "We plan to do a demonstration of facial recognition bias through a live demo in a Jupyter notebook. This will cover the “History of Racial Bias in Facial Detection Algorithms” section in our presentation, and the “empty” demo notebook(?) will be available for students to download pre-presentation day. The objective of this demo, as stated previously, is to show the real-time effects of face detection racial bias, and how those problems can extend beyond a notebook.\n",
    "\n",
    "In the notebook exercise, students will be implementing a pre-trained model to help label face images in a provided dataset, which will be a subset of the CelebA faces dataset. This dataset contains hundreds of thousands of face images with provided feature labels, including race. For the sake of computation time we will provide students with only a subset of this data to have the model make predictions from. They will have access to documentation which will demonstrate how to properly use the model, and will use this documentation to help fill out a provided code skeleton. As we go through the notebook and implement the code, we will also be discussing the discrepancies between the model’s predictions and the true labels of the face detection algorithms (in this case, the labels will be based on race). By doing so, we allow the students to see the real-time effects of racial biases through machine learning algorithms play out.\n",
    "\n",
    "Overall, this exercise will help encourage students to look further into the ethics of using machine learning algorithms (artificial intelligence) to conduct everyday procedures such as facial recognition/detection. It should demonstrate to students that using AI for facial detection is not fully reliable and can be influenced by several factors including the data it is trained on. The estimated runtime for the exercise is around 10-15 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates\n",
    "- May 31, 2024 (Friday, Week 9)\n",
    "- June 3, 2024 (Monday, Week 10)\n",
    "- June 5, 2024 (Wednesday, Week 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout our project working, we will create/facilitate a healthy group work environment by abiding by these guidelines:\n",
    "- *Communicating via text and discord*\n",
    "- *Handling conflict by openly communicating about standards and expectations*\n",
    "- *Making decisions via group chat, and letting team members know if obstacles arise early on*\n",
    "- *Following the proposed timeline deadlines on time/earlier on*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 04/28  |  3PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; create outline | \n",
    "| 05/08  |  3PM |  Do background research on topic (all) | Discuss ideal exercises; draft project proposal | \n",
    "| 05/17  | 3PM  | Edit, finalize, and submit proposal; (all) | Start slide deck; Assign group members to lead each specific part   |\n",
    "| 05/20  | 3PM  | Write intro and history background info (all) | Review/Edit intro and history; Discuss code examples to assist written info |\n",
    "| 05/23  | 3PM  | Finalize intro/history; Begin case studies and ethics (all) | Discuss/edit case studies; Complete ethics |\n",
    "| 05/27  | 3PM  | Draft solutions (all) | Discuss/edit full project |\n",
    "| 05/31  | 2PM | Finish slide deck | Present Project  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
